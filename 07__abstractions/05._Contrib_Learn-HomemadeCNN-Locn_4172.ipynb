{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homemade CNN with contrib.learn\n",
    "1. Learning TensorFlow: A Guide to Building Deep Learning Systems (Kindle Location 4172). O'Reilly Media. Kindle Edition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "DATA_DIR = '/home/rm/tmp/data' #if not 'win32' in sys.platform else \"c:\\\\tmp\\\\data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom CNN Estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(x, target, mode, params):\n",
    "    y_ = tf.cast(target, tf.float32)\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    # Conv layer 1\n",
    "    conv1 = layers.convolution2d(x_image, 32, [5,5],\n",
    "                activation_fn=tf.nn.relu,\n",
    "                biases_initializer=tf.constant_initializer(0.1),\n",
    "                weights_initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    pool1 = layers.max_pool2d(conv1, [2,2])\n",
    "\n",
    "    # Conv layer 2\n",
    "    conv2 = layers.convolution2d(pool1, 64, [5,5],\n",
    "                activation_fn=tf.nn.relu,\n",
    "                biases_initializer=tf.constant_initializer(0.1),\n",
    "                weights_initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    pool2 = layers.max_pool2d(conv2, [2,2])\n",
    "\n",
    "    # FC layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7*7*64])\n",
    "    fc1 = layers.fully_connected(pool2_flat, 1024,\n",
    "              activation_fn=tf.nn.relu,\n",
    "              biases_initializer=tf.constant_initializer(0.1),\n",
    "              weights_initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    fc1_drop = layers.dropout(fc1, keep_prob=params[\"dropout\"],\n",
    "        is_training=(mode == 'train'))\n",
    "\n",
    "    # readout layer\n",
    "    y_conv = layers.fully_connected(fc1_drop, 10, activation_fn=None)\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=cross_entropy,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adam\")\n",
    "\n",
    "    predictions = tf.argmax(y_conv, 1)\n",
    "    return predictions, cross_entropy, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "x_data, y_data = data.train.images,np.int32(data.train.labels)\n",
    "tf.cast(x_data,tf.float32)\n",
    "tf.cast(y_data,tf.float32)\n",
    "\n",
    "model_params = {\"learning_rate\": 1e-4, \"dropout\": 0.5}\n",
    "\n",
    "MAX_TRAINING_STEPS = 500   #5000\n",
    "BATCH_SIZE_TRAINING = 50\n",
    "BATCH_SIZE_TEST = 2000\n",
    "NO_OF_TEST_ITERS = 5\n",
    "\n",
    "CNN = tf.contrib.learn.Estimator(\n",
    "    model_fn=model_fn, params=model_params)\n",
    "\n",
    "print(\"\\nStarting training for %s steps max\\n\" % MAX_TRAINING_STEPS)\n",
    "CNN.fit(x=data.train.images,\n",
    "        y=data.train.labels, batch_size=BATCH_SIZE_TRAINING,\n",
    "        max_steps=MAX_TRAINING_STEPS)\n",
    "\n",
    "test_acc = 0\n",
    "for ii in range(NO_OF_TEST_ITERS):\n",
    "    batch = data.test.next_batch(BATCH_SIZE_TEST)\n",
    "    predictions = list(CNN.predict(batch[0], as_iterable=True))\n",
    "    test_acc = test_acc + (np.argmax(batch[1],1) == predictions).mean()\n",
    "\n",
    "print(test_acc/NO_OF_TEST_ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
