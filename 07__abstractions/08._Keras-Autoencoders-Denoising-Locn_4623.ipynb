{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a toy CNN autoencoder with Keras.\n",
    "1. Learning TensorFlow: A Guide to Building Deep Learning Systems (Kindle Locations 4623-4624). O'Reilly Media. Kindle Edition. \n",
    "2. current practical applications are mostly for extracting lower-dimensional representations, denoising data, and data visualization with reduced dimensionality. Denoising works because the network learns the important abstractions of the image, while losing unimportant image-specific signals like noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read automobile images and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras # keras now available from tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "CLASS_AUTOMOBILE = 1\n",
    "HORIZ_PIXELS = VERT_PIXELS = 32; NUM_OF_CHANNELS = 3\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#x_train = x_train[np.where(y_train==CLASS_AUTOMOBILE)[0],:,:,:]\n",
    "#x_test = x_test[np.where(y_test==CLASS_AUTOMOBILE)[0],:,:,:]\n",
    "\n",
    "#The following works just as well as the ones above.\n",
    "\n",
    "x_train = x_train[np.where(y_train==CLASS_AUTOMOBILE)[0]]\n",
    "x_test = x_test[np.where(y_test==CLASS_AUTOMOBILE)[0]]\n",
    "\n",
    "#print(\"x_train no of pictures: \", len(x_train), \"Shape: \", x_train.shape)\n",
    "#print(\"x_test no of pictures: \", len(x_test), \"Shape: \", x_test.shape)\n",
    "assert((HORIZ_PIXELS, VERT_PIXELS, NUM_OF_CHANNELS) == (x_train.shape[1], \\\n",
    "                                                        x_train.shape[2], \\\n",
    "                                                        x_train.shape[3]))\n",
    "assert((HORIZ_PIXELS, VERT_PIXELS, NUM_OF_CHANNELS) == (x_test.shape[1], \\\n",
    "                                                        x_test.shape[2], \\\n",
    "                                                        x_test.shape[3]))\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "assert not x_train.any() > 1.0\n",
    "assert not x_test.any() > 1.0\n",
    "assert not x_train.any() < 0.0\n",
    "assert not x_test.any() < 0.0\n",
    "\n",
    "NOISE_MEAN = 0.0; NOISE_STD_DEV = 0.4\n",
    "NOISE_GAIN = 0.5\n",
    "\n",
    "x_train_plusNoise = x_train + NOISE_GAIN *\\\n",
    "                         np.random.normal(loc=NOISE_MEAN, \\\n",
    "                                          scale=NOISE_STD_DEV, \\\n",
    "                                          size=x_train.shape) \n",
    "\n",
    "x_test_plusNoise = x_test + NOISE_GAIN *\\\n",
    "                         np.random.normal(loc=NOISE_MEAN, \\\n",
    "                                          scale=NOISE_STD_DEV, \\\n",
    "                                          size=x_test.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((x_test_plusNoise).max())\n",
    "#print((x_train_plusNoise).max())\n",
    "assert not(x_train_plusNoise.any() > ((x_train_plusNoise).max() - 0.0))\n",
    "assert not(x_test_plusNoise.any() > ((x_test_plusNoise).max() - 0.0E-00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_CLIP = 1.0; BOTTOM_CLIP = 0.0 #Pixel values are non-negative. They are unsigned byte.\n",
    "# Keep the values in the range [0, TOP_CLIP]. \n",
    "# Why?\n",
    "x_train_plusNoise = np.clip(x_train_plusNoise, 0., TOP_CLIP)\n",
    "x_test_plusNoise = np.clip(x_test_plusNoise, 0., TOP_CLIP)\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer\n",
    "#It is generally recommend to use the functional layer API via Input, \n",
    "#(which creates an InputLayer) without directly using InputLayer\n",
    "inp_img = Input(shape=(HORIZ_PIXELS, VERT_PIXELS, NUM_OF_CHANNELS))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a small SANDBOX.\n",
    "#Taken from https://keras.io/getting-started/functional-api-guide/#the-concept-of-layer-node\n",
    "a = Input(shape=(280, 256))\n",
    "\n",
    "#lstm = LSTM(32)\n",
    "lstm = Conv2D(32, #filters: Integer, the dimensionality of the output space\n",
    "            (3, 3), # height and width of the 2D convolution window\n",
    "            activation='relu', \n",
    "            padding='same')\n",
    "encoded_a = lstm(inp_img)\n",
    "\n",
    "assert lstm.output == encoded_a, \"This should NOT fail\"\n",
    "# END of SANDBOX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the layers of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STD_NUM_OF_FEATURES = 32\n",
    "NUM_OF_FEATURES = STD_NUM_OF_FEATURES * 2\n",
    "CONV_WINDOW_EDGE = 3\n",
    "\n",
    "conv2d_op= Conv2D(NUM_OF_FEATURES, #filters: Integer, the dimensionality of the output space\n",
    "            (CONV_WINDOW_EDGE, CONV_WINDOW_EDGE), # height and width of the 2D convolution window\n",
    "            activation='relu', \n",
    "            padding='same')\n",
    "img = conv2d_op(inp_img)\n",
    "assert conv2d_op.input == inp_img\n",
    "assert conv2d_op.input_shape == (None, HORIZ_PIXELS, VERT_PIXELS, NUM_OF_CHANNELS)\n",
    "assert conv2d_op.output == img\n",
    "assert conv2d_op.output_shape == (None, HORIZ_PIXELS, VERT_PIXELS, NUM_OF_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POOL_FACTOR = 4\n",
    "max_pool_op = MaxPooling2D((POOL_FACTOR, POOL_FACTOR), padding='same')\n",
    "img = max_pool_op(img)\n",
    "\n",
    "assert max_pool_op.input_shape == (None,HORIZ_PIXELS,VERT_PIXELS,NUM_OF_FEATURES)\n",
    "assert max_pool_op.output_shape == (None, HORIZ_PIXELS//POOL_FACTOR, VERT_PIXELS//POOL_FACTOR, NUM_OF_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_op = Conv2D(NUM_OF_FEATURES, (CONV_WINDOW_EDGE, CONV_WINDOW_EDGE), activation='relu', padding='same')\n",
    "img = conv2d_op(img)\n",
    "assert conv2d_op.input_shape == (None, HORIZ_PIXELS//POOL_FACTOR, VERT_PIXELS//POOL_FACTOR, NUM_OF_FEATURES)\n",
    "assert conv2d_op.output_shape == (None, HORIZ_PIXELS//POOL_FACTOR, VERT_PIXELS//POOL_FACTOR, NUM_OF_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_op = Conv2D(NUM_OF_FEATURES, (CONV_WINDOW_EDGE, CONV_WINDOW_EDGE), activation='relu', padding='same')\n",
    "img = conv2d_op(img)\n",
    "assert conv2d_op.input_shape == (None, HORIZ_PIXELS//POOL_FACTOR, VERT_PIXELS//POOL_FACTOR, NUM_OF_FEATURES)\n",
    "assert conv2d_op.output_shape == (None, HORIZ_PIXELS//POOL_FACTOR, VERT_PIXELS//POOL_FACTOR, NUM_OF_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_sampling_op = UpSampling2D((POOL_FACTOR, POOL_FACTOR))\n",
    "img = up_sampling_op(img)\n",
    "assert up_sampling_op.input_shape == (None, HORIZ_PIXELS//POOL_FACTOR, VERT_PIXELS//POOL_FACTOR, NUM_OF_FEATURES)\n",
    "assert up_sampling_op.output_shape == (None, HORIZ_PIXELS, VERT_PIXELS, NUM_OF_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_op = Conv2D(NUM_OF_CHANNELS, (CONV_WINDOW_EDGE, CONV_WINDOW_EDGE), activation='sigmoid', padding='same')\n",
    "decoded = decode_op(img)\n",
    "\n",
    "assert(decode_op.input_shape == (None, HORIZ_PIXELS, VERT_PIXELS, NUM_OF_FEATURES))\n",
    "assert decode_op.output_shape == (None, HORIZ_PIXELS, VERT_PIXELS, NUM_OF_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Autoencoder.\n",
    "1. The two ends of the sequence of definitions above are used to completely specify the layers of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/api_docs/python/tf/keras/models\n",
    "autoencoder = Model(inp_img, decoded)\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/losses/binary_crossentropy\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/backend/binary_crossentropy\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the two callback functions to be used by the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./models/autoencoder',\\\n",
    "              histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "#Learning TensorFlow: A Guide to Building Deep Learning Systems (Kindle Location 4685). \n",
    "#O'Reilly Media. Kindle Edition. \n",
    "model_saver = ModelCheckpoint(\n",
    "                    filepath='./models/autoencoder/epochs_50-NOISE_GAIN_0.5-MEAN_0.0-VAR_0.4',\\\n",
    "                     verbose=0, period=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "autoencoder.fit(x_train_plusNoise, x_train,\n",
    "                epochs=NO_OF_EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_plusNoise, x_test),\n",
    "                callbacks=[tensorboard, model_saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "n_imgs = 10\n",
    "_,axarr = plt.subplots(3,n_imgs,figsize=[20,5])\n",
    "decoded_imgs = autoencoder.predict(x_test_plusNoise)\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    \n",
    "    ax = axarr[0,i]\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.imshow(x_test_plusNoise[i,:,:,:])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = axarr[1,i]\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.imshow(decoded_imgs[i,:,:,:])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "    ax = axarr[2,i]\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.imshow(x_test[i,:,:,:])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
