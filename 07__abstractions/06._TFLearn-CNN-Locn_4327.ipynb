{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFLearn\n",
    "### CNN\n",
    "1. See Learning TensorFlow: A Guide to Building Deep Learning Systems \n",
    "..1. (Kindle Location 4327).\n",
    "..2. thru (Kindle Location 4418).\n",
    "2. In the following code we use the same CNN used earlier for the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Data loading and basic trasformations\n",
    "import tflearn.datasets.mnist as mnist\n",
    "X, Y, X_test, Y_test = mnist.load_data(one_hot=True)\n",
    "X = X.reshape([-1, 28, 28, 1])\n",
    "X_test = X_test.reshape([-1, 28, 28, 1])\n",
    "\n",
    "# Building the network\n",
    "CNN = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "CNN = conv_2d(CNN, 32, 5, activation='relu', regularizer=\"L2\")\n",
    "CNN = max_pool_2d(CNN, 2)\n",
    "CNN = local_response_normalization(CNN)\n",
    "CNN = conv_2d(CNN, 64, 5, activation='relu', regularizer=\"L2\")\n",
    "CNN = max_pool_2d(CNN, 2)\n",
    "CNN = local_response_normalization(CNN)\n",
    "CNN = fully_connected(CNN, 1024, activation=None)\n",
    "CNN = dropout(CNN, 0.5)\n",
    "CNN = fully_connected(CNN, 10, activation='softmax')\n",
    "CNN = regression(CNN, optimizer='adam', learning_rate=0.0001,\n",
    "                     loss='categorical_crossentropy', name='target')\n",
    "\n",
    "# Training the network\n",
    "model = tflearn.DNN(CNN,tensorboard_verbose=0,tensorboard_dir = 'MNIST_tflearn_board/',\\\n",
    "                    checkpoint_path = 'MNIST_tflearn_checkpoints/checkpoint')\n",
    "model.fit({'input': X}, {'target': Y}, n_epoch=3, \n",
    "           validation_set=({'input': X_test}, {'target': Y_test}),\n",
    "           snapshot_step=1000,show_metric=True, run_id='convnet_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. After fitting the model, we evaluate performance on the test data: Learning TensorFlow: A Guide to Building Deep Learning Systems (Kindle Location 4408). O'Reilly Media. Kindle Edition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate({'input': X_test},{'target': Y_test})\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ...and form new predictions (using them here again as a “sanity check” to the previous evaluation):Learning TensorFlow: A Guide to Building Deep Learning Systems (Kindle Location 4412). O'Reilly Media. Kindle Edition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict({'input': X_test})\n",
    "#Typo in the book code\n",
    "#print((np.argmax(testY,1)==np.argmax(pred,1)).mean())\n",
    "print((np.argmax(Y_test,1)==np.argmax(pred,1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
